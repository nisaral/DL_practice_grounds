{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":643971,"sourceType":"datasetVersion","datasetId":319080},{"sourceId":3235,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":2401,"modelId":288}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T11:36:54.185612Z","iopub.execute_input":"2024-12-23T11:36:54.185955Z","iopub.status.idle":"2024-12-23T11:37:12.322529Z","shell.execute_reply.started":"2024-12-23T11:36:54.185916Z","shell.execute_reply":"2024-12-23T11:37:12.321335Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Check train directory contents\ntrain_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train'\nprint(\"Train directory contents:\")\nfor class_dir in os.listdir(train_dir):\n    print(f\"{class_dir}: {len(os.listdir(os.path.join(train_dir, class_dir)))}\")\n\n# Check TensorFlow and library versions\nprint(\"\\nLibrary Versions:\")\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Keras version:\", tf.keras.__version__)\n\n# Print class details from data generator\ntrain_datagen = ImageDataGenerator(rescale=1/255.)\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                               target_size=(224, 224),\n                                               batch_size=25,\n                                               class_mode='categorical')\n\nprint(\"\\nClass indices:\")\nprint(train_data.class_indices)\n\n# Verify a batch of data\nfor images, labels in train_data:\n    print(\"\\nSample batch:\")\n    print(\"Images shape:\", images.shape)\n    print(\"Labels shape:\", labels.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T11:38:15.871346Z","iopub.execute_input":"2024-12-23T11:38:15.871738Z","iopub.status.idle":"2024-12-23T11:38:27.048703Z","shell.execute_reply.started":"2024-12-23T11:38:15.871711Z","shell.execute_reply":"2024-12-23T11:38:27.047591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n\ntrain_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train' \n\ntest_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test' \n\n\n\ntrain_datagen = ImageDataGenerator(rescale=1/255.)\n\ntest_datagen = ImageDataGenerator(rescale=1/255.)\n\n\n\ntrain_data = train_datagen.flow_from_directory(train_dir,\n\n                                               target_size = (224,224),\n\n                                               batch_size=25,\n\n                                               class_mode ='categorical'\n\n                                               )\n\ntest_data = test_datagen.flow_from_directory(test_dir,\n\n                                               target_size = (224,224),\n\n                                               batch_size=25,\n\n                                               class_mode ='categorical'\n\n                                               )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T11:39:02.709584Z","iopub.execute_input":"2024-12-23T11:39:02.710258Z","iopub.status.idle":"2024-12-23T11:39:04.304582Z","shell.execute_reply.started":"2024-12-23T11:39:02.710220Z","shell.execute_reply":"2024-12-23T11:39:04.303548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Generator Model\ndef build_generator(latent_dim):\n    model = tf.keras.Sequential([\n        layers.Dense(7*7*256, input_dim=latent_dim),\n        layers.Reshape((7, 7, 256)),\n        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'),\n        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'),\n        layers.Conv2D(3, kernel_size=7, activation='tanh', padding='same')\n    ])\n    return model\n\n# Discriminator Model\ndef build_discriminator(img_shape):\n    model = tf.keras.Sequential([\n        layers.Conv2D(64, kernel_size=4, strides=2, input_shape=img_shape, padding='same', activation='relu'),\n        layers.Flatten(),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Generator Model\ndef build_generator(latent_dim):\n    model = tf.keras.Sequential([\n        layers.Dense(7*7*256, input_dim=latent_dim),\n        layers.Reshape((7, 7, 256)),\n        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'),\n        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'),\n        layers.Conv2D(3, kernel_size=7, activation='tanh', padding='same')\n    ])\n    return model\n\n# Discriminator Model\ndef build_discriminator(img_shape):\n    model = tf.keras.Sequential([\n        layers.Conv2D(64, kernel_size=4, strides=2, input_shape=img_shape, padding='same', activation='relu'),\n        layers.Flatten(),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}